只有一个简单的match子句的查询是很少的。我们经常需要在一个或者多个字段中查询相同的或者不同的查询字符串，意味着我们需要能够组合多个查询子句以及使他们的相关性得分有意义。

或许我们在寻找列夫·托尔斯泰写的一本叫《战争与和平》的书。或许我们在Elasticsearch的文档中查找minimum should match，它可能在标题中，或者在一页的正文中。或许我们查找名为John，姓为Smith的人。

在这一章节，我们会介绍用于构建多个查询子句搜索的可能的工具，以及怎么样选择解决方案来应用到你特殊的场景。

14.1 多重查询字符串

    （1）多重查询字符串
    在明确的字段中的词查询是最容易处理的多字段查询。如果我们知道War and Peace是标题，Leo Tolstoy是作者，可以很容易的用match查询表达每个条件，并且用布尔查询组合起来：
    GET /_search
    {
      "query": {
        "bool": {
          "should": [
            { "match": { "title":  "War and Peace" }},
            { "match": { "author": "Leo Tolstoy"   }}
          ]
        }
      }
    }
    布尔查询采用"匹配越多越好(More-matches-is-better)"的方法，所以每个match子句的得分会被加起来变成最后的每个文档的得分。匹配两个子句的文档的得分会比只匹配了一个文档的得分高。
    当然，没有限制你只能使用match子句：布尔查询可以包装任何其他的查询类型，包含其他的布尔查询，我们可以添加一个子句来指定我们更喜欢看被哪个特殊的翻译者翻译的那版书：
    GET /_search
    {
      "query": {
        "bool": {
          "should": [
            { "match": { "title":  "War and Peace" }},
            { "match": { "author": "Leo Tolstoy"   }},
            { "bool":  {
              "should": [
                { "match": { "translator": "Constance Garnett" }},
                { "match": { "translator": "Louise Maude"      }}
              ]
            }}
          ]
        }
      }
    }
    为什么我们把翻译者的子句放在一个独立的布尔查询中？所有的匹配查询都是should子句，所以为什么不把翻译者的子句放在和title以及作者的同一级？
    答案就在如何计算得分中。布尔查询执行每个匹配查询，把他们的得分加在一起，然后乘以匹配子句的数量，并且除以子句的总数。每个同级的子句权重是相同的。
    在前面的查询中，包含翻译者的布尔查询占用总得分的三分之一。如果我们把翻译者的子句放在和标题与作者同级的目录中，我们会把标题与作者的作用减少的四分之一。

    （2）设置子句优先级
    在先前的查询中我们可能不需要使每个子句都占用三分之一的权重。我们可能对标题以及作者比翻译者更感兴趣。我们需要调整查询来使得标题和作者的子句相关性更重要。
    最简单的方法是使用boost参数。为了提高标题和作者字段的权重，我们给boost参数提供一个比1高的值：
    GET /_search
    {
     "query": {
       "bool": {
         "should": [
           { "match": { <1>
               "title":  {
                 "query": "War and Peace",
                 "boost": 2
           }}},
           { "match": { <1>
               "author":  {
                 "query": "Leo Tolstoy",
                 "boost": 2
           }}},
           { "bool":  { <2>
               "should": [
                 { "match": { "translator": "Constance Garnett" }},
                 { "match": { "translator": "Louise Maude"      }}
               ]
           }}
         ]
       }
     }
    }
    <1> 标题和作者的boost值为2。
    <2> 嵌套的布尔查询的boost值为默认的1。
    通过试错(Trial and Error)的方式可以确定"最佳"的boost值：设置一个boost值，执行测试查询，重复这个过程。一个合理boost值的范围在1和10之间，也可能是15。
    比它更高的值的影响不会起到很大的作用，因为分值会被规范化(Normalized)。

14.2 单一查询字符串

    （1）单一查询字符串
    bool查询是多字段查询的中流砥柱。在很多场合下它都能很好地工作，特别是当你能够将不同的查询字符串映射到不同的字段时。
    问题在于，现在的用户期望能够在一个地方输入所有的搜索词条，然后应用能够知道如何为他们得到正确的结果。
    所以当我们把含有多个字段的搜索表单称为高级搜索(Advanced Search)时，是有一些讽刺意味的。高级搜索虽然对用户而言会显得更"高级"，但是实际上它的实现方式更简单。
    对于多词，多字段查询并没有一种万能(one-size-fits-all)的方法。要得到最佳的结果，你需要了解你的数据以及如何使用恰当的工具。

    （2）了解你的数据
    当用户的唯一输入就是一个查询字符串时，你会经常碰到以下三种情况：
    1.最佳字段(Best fields)
        当搜索代表某些概念的单词时，例如"brown fox"，几个单词合在一起表达出来的意思比单独的单词更多。类似title和body的字段，尽管它们是相关联的，但是也是互相竞争着的。
        文档在相同的字段中应该有尽可能多的单词(译注：搜索的目标单词)，文档的分数应该来自拥有最佳匹配的字段。
    2.多数字段(Most fields)
        一个用来调优相关度的常用技术是将相同的数据索引到多个字段中，每个字段拥有自己的分析链(Analysis Chain)。
        主要字段会含有单词的词干部分，同义词和消除了变音符号的单词。它用来尽可能多地匹配文档。
        相同的文本可以被索引到其它的字段中来提供更加精确的匹配。一个字段或许会包含未被提取成词干的单词，另一个字段是包含了变音符号的单词，第三个字段则使用shingle来提供关于单词邻近度(Word Proximity)的信息。
        以上这些额外的字段扮演者signal的角色，用来增加每个匹配的文档的相关度分值。越多的字段被匹配则意味着文档的相关度越高。
    3.跨字段(Cross fields)
        对于一些实体，标识信息会在多个字段中出现，每个字段中只含有一部分信息：
        Person: first_name 和 last_name
        Book: title, author, 和 description
        Address: street, city, country, 和 postcode
        此时，我们希望在任意字段中找到尽可能多的单词。我们需要在多个字段中进行查询，就好像这些字段是一个字段那样。
    以上这些都是多词，多字段查询，但是每种都需要使用不同的策略。我们会在本章剩下的部分解释每种策略。

14.3 最佳字段

    （1）最佳字段
    假设我们有一个让用户搜索博客文章的网站(允许多字段搜索，最佳字段查询)，就像这两份文档一样：
    PUT /my_index/my_type/1
    {
        "title": "Quick brown rabbits",
        "body":  "Brown rabbits are commonly seen."
    }
    PUT /my_index/my_type/2
    {
        "title": "Keeping pets healthy",
        "body":  "My quick brown fox eats rabbits on a regular basis."
    }
    用户输入了"Brown fox"，然后按下了搜索键。我们无法预先知道用户搜索的词条会出现在博文的title或者body字段中，但是用户是在搜索和他输入的单词相关的内容。
    肉眼观察，以上的两份文档中，文档2似乎匹配的更好一些，因为它包含了用户寻找的两个单词。
    让我们运行下面的bool查询：
    {
        "query": {
            "bool": {
                "should": [
                    { "match": { "title": "Brown fox" }},
                    { "match": { "body":  "Brown fox" }}
                ]
            }
        }
    }
    然后我们发现文档1的分值更高：
    {
      "hits": [
         {
            "_id":      "1",
            "_score":   0.14809652,
            "_source": {
               "title": "Quick brown rabbits",
               "body":  "Brown rabbits are commonly seen."
            }
         },
         {
            "_id":      "2",
            "_score":   0.09256032,
            "_source": {
               "title": "Keeping pets healthy",
               "body":  "My quick brown fox eats rabbits on a regular basis."
            }
         }
      ]
    }
    要理解原因，想想bool查询是如何计算得到其分值的：
        1.运行should子句中的两个查询
        2.相加查询返回的分值
        3.将相加得到的分值乘以匹配的查询子句的数量
        4.除以总的查询子句的数量
    文档1在两个字段中都包含了brown，因此两个match查询都匹配成功并拥有了一个分值。文档2在body字段中包含了brown以及fox，但是在title字段中没有出现任何搜索的单词。
    因此对body字段查询得到的高分加上对title字段查询得到的零分，然后在乘以匹配的查询子句数量1，最后除以总的查询子句数量2，导致整体分值比文档1的低。

    在这个例子中，title和body字段是互相竞争的。我们想要找到一个最佳匹配(Best-matching)的字段。
    如果我们不是合并来自每个字段的分值，而是使用最佳匹配字段的分值作为整个查询的整体分值呢？这就会让包含有我们寻找的两个单词的字段有更高的权重，而不是在不同的字段中重复出现的相同单词。

    （2）dis_max查询
    相比使用bool查询，我们可以使用dis_max查询(Disjuction Max Query)。Disjuction的意思"OR"(而Conjunction的意思是"AND")，因此Disjuction Max Query的意思就是返回匹配了任何查询的文档，并且分值是产生了最佳匹配的查询所对应的分值：
    {
        "query": {
            "dis_max": {
                "queries": [
                    { "match": { "title": "Brown fox" }},
                    { "match": { "body":  "Brown fox" }}
                ]
            }
        }
    }
    它会产生我们期望的结果:
    {
      "hits": [
         {
            "_id":      "2",
            "_score":   0.21509302,
            "_source": {
               "title": "Keeping pets healthy",
               "body":  "My quick brown fox eats rabbits on a regular basis."
            }
         },
         {
            "_id":      "1",
            "_score":   0.12713557,
            "_source": {
               "title": "Quick brown rabbits",
               "body":  "Brown rabbits are commonly seen."
            }
         }
      ]
    }

14.4 最佳字段查询调优

    （1）最佳字段查询的调优
    如果用户搜索的是"quick pets"，那么会发生什么呢？两份文档都包含了单词quick，但是只有文档2包含了单词pets。两份文档都没能在一个字段中同时包含搜索的两个单词。
    一个像下面那样的简单dis_max查询会选择出拥有最佳匹配字段的查询子句，而忽略其他的查询子句：
    {
        "query": {
            "dis_max": {
                "queries": [
                    { "match": { "title": "Quick pets" }},
                    { "match": { "body":  "Quick pets" }}
                ]
            }
        }
    }
    {
      "hits": [
         {
            "_id": "1",
            "_score": 0.12713557, <1>
            "_source": {
               "title": "Quick brown rabbits",
               "body": "Brown rabbits are commonly seen."
            }
         },
         {
            "_id": "2",
            "_score": 0.12713557, <1>
            "_source": {
               "title": "Keeping pets healthy",
               "body": "My quick brown fox eats rabbits on a regular basis."
            }
         }
       ]
    }
    <1> 可以发现，两份文档的分值是一模一样的。
    我们期望的是同时匹配了title字段和body字段的文档能够拥有更高的排名，但是结果并非如此。需要记住：dis_max查询只是简单的使用最佳匹配查询子句得到的_score。

    （2）tie_breaker
    但是，将其它匹配的查询子句考虑进来也是可能的。通过指定tie_breaker参数：
    {
        "query": {
            "dis_max": {
                "queries": [
                    { "match": { "title": "Quick pets" }},
                    { "match": { "body":  "Quick pets" }}
                ],
                "tie_breaker": 0.3
            }
        }
    }
    它会返回以下结果：
    {
      "hits": [
         {
            "_id": "2",
            "_score": 0.14757764, <1>
            "_source": {
               "title": "Keeping pets healthy",
               "body": "My quick brown fox eats rabbits on a regular basis."
            }
         },
         {
            "_id": "1",
            "_score": 0.124275915, <1>
            "_source": {
               "title": "Quick brown rabbits",
               "body": "Brown rabbits are commonly seen."
            }
         }
       ]
    }
    <1> 现在文档2的分值比文档1稍高一些。
    tie_breaker参数会让dis_max查询的行为更像是dis_max和bool的一种折中。它会通过下面的方式改变分值计算过程：
        1.取得最佳匹配查询子句的_score。
        2.将其它每个匹配的子句的分值乘以tie_breaker。
        3.将以上得到的分值进行累加并规范化。
    通过tie_breaker参数，所有匹配的子句都会起作用，只不过最佳匹配子句的作用更大。
    提示：tie_breaker的取值范围是0到1之间的浮点数，取0时即为仅使用最佳匹配子句(译注：和不使用tie_breaker参数的dis_max查询效果相同)，取1则会将所有匹配的子句一视同仁。
    它的确切值需要根据你的数据和查询进行调整，但是一个合理的值会靠近0，(比如，0.1 -0.4)，来确保不会压倒dis_max查询具有的最佳匹配性质。

14.5 多重匹配查询

    （1）multi_match查询
    multi_match查询提供了一个简便的方法用来对多个字段执行相同的查询。
    提示：存在几种类型的multi_match查询，其中的3种正好和在"单一查询字符串"小节中"了解你的数据"单元中提到的几种类型相同：best_fields，most_fields以及cross_fields。
    默认情况下，该查询以best_fields类型执行，它会为每个字段生成一个match查询，然后将这些查询包含在一个dis_max查询中。下面的dis_max查询：
    {
      "dis_max": {
        "queries":  [
          {
            "match": {
              "title": {
                "query": "Quick brown fox",
                "minimum_should_match": "30%"
              }
            }
          },
          {
            "match": {
              "body": {
                "query": "Quick brown fox",
                "minimum_should_match": "30%"
              }
            }
          },
        ],
        "tie_breaker": 0.3
      }
    }
    可以通过multi_match简单地重写如下：
    {
        "multi_match": {
            "query": "Quick brown fox",
            "type": "best_fields", <1>
            "fields": [ "title", "body" ],
            "tie_breaker": 0.3,
            "minimum_should_match": "30%" <2>
        }
    }
    <1> 注意到以上的type属性为best_fields。
    <2> minimum_should_match和operator参数会被传入到生成的match查询中。

    （2）在字段名中使用通配符
    字段名可以通过通配符指定：任何匹配了通配符的字段都会被包含在搜索中。你可以通过下面的查询来匹配book_title，chapter_title以及section_title字段：
    {
        "multi_match": {
            "query":  "Quick brown fox",
            "fields": "*_title"
        }
    }

    （3）加权个别字段
    个别字段可以通过caret语法(^)进行加权：仅需要在字段名后添加^boost，其中的boost是一个浮点数：
    {
        "multi_match": {
            "query":  "Quick brown fox",
            "fields": [ "*_title", "chapter_title^2" ] <1>
        }
    }
    <1> chapter_title字段的boost值为2，而book_title和section_title字段的boost值为默认的1。

14.6 最多字段查询

    （1）多数字段
    全文搜索是一场召回率(Recall)-返回所有相关的文档，以及准确率(Precision)-不返回无关文档，之间的战斗。目标是在结果的第一页给用户呈现最相关的文档。
    为了提高召回率，我们会广撒网-不仅包括精确匹配了用户搜索词条的文档，还包括了那些我们认为和查询相关的文档。如果一个用户搜索了"quick brown fox"，
    一份含有fast foxes的文档也可以作为一个合理的返回结果。

    如果我们拥有的相关文档仅仅是含有fast foxes的文档，那么它会出现在结果列表的顶部。但是如果我们有100份含有quick brown fox的文档，
    那么含有fast foxes的文档的相关性就会变低，我们希望它出现在结果列表的后面。在包含了许多可能的匹配后，我们需要确保相关度高的文档出现在顶部。

    一个用来调优全文搜索相关性的常用技术是将同样的文本以多种方式索引，每一种索引方式都提供了不同相关度的信号(Signal)。
    主要字段(Main field)中含有的词条的形式是最宽泛的(Broadest-matching)，用来尽可能多的匹配文档。比如，我们可以这样做：
        使用一个词干提取器来将jumps，jumping和jumped索引成它们的词根：jump。然后当用户搜索的是jumped时，我们仍然能够匹配含有jumping的文档。
        包含同义词，比如jump，leap和hop。
        移除变音符号或者声调符号：比如，ésta，está和esta都会以esta被索引。但是，如果我们有两份文档，其中之一含有jumped，而另一份含有jumping，那么用户会希望第一份文档的排序会靠前，因为它含有用户输入的精确值。
    我们可以通过将相同的文本索引到其它字段来提供更加精确的匹配。一个字段可以包含未被提取词干的版本，另一个则是含有变音符号的原始单词，然后第三个使用了shingles，用来提供和单词邻近度相关的信息。
    这些其它字段扮演的角色就是信号(Signals)，它们用来增加每个匹配文档的相关度分值。能够匹配的字段越多，相关度就越高。
    如果一份文档能够匹配具有最宽泛形式的主要字段(Main field)，那么它就会被包含到结果列表中。如果它同时也匹配了信号字段，它会得到一些额外的分值用来将它移动到结果列表的前面。
    我们会在本书的后面讨论同义词，单词邻近度，部分匹配以及其他可能的信号，但是我们会使用提取了词干和未提取词干的字段的简单例子来解释这个技术。

    （2）多字段映射
    第一件事就是将我们的字段索引两次：一次是提取了词干的形式，一次是未提取词干的形式。为了实现它，我们会使用多字段(Multifields)，在字符串排序和多字段中我们介绍过：
    DELETE /my_index
    PUT /my_index
    {
        "settings": { "number_of_shards": 1 }, <1>
        "mappings": {
            "my_type": {
                "properties": {
                    "title": { <2>
                        "type":     "string",
                        "analyzer": "english",
                        "fields": {
                            "std":   { <3>
                                "type":     "string",
                                "analyzer": "standard"
                            }
                        }
                    }
                }
            }
        }
    }
    <1> See <<关联失效(相关性被破坏>>.
    <2> title字段使用了english解析器进行词干提取。
    <3> title.std字段则使用的是standard解析器，因此它没有进行词干提取。
    下一步，我们会索引一些文档：
    PUT /my_index/my_type/1
    { "title": "My rabbit jumps" }
    PUT /my_index/my_type/2
    { "title": "Jumping jack rabbits" }
    以下是一个简单的针对title字段的match查询，它查询jumping rabbits：
    GET /my_index/_search
    {
       "query": {
            "match": {
                "title": "jumping rabbits"
            }
        }
    }
    它会变成一个针对两个提干后的词条jump和rabbit的查询，这要得益于english解析器。两份文档的title字段都包含了以上两个词条，因此两份文档的分值是相同的：
    {
      "hits": [
         {
            "_id": "1",
            "_score": 0.42039964,
            "_source": {
               "title": "My rabbit jumps"
            }
         },
         {
            "_id": "2",
            "_score": 0.42039964,
            "_source": {
               "title": "Jumping jack rabbits"
            }
         }
      ]
    }
    如果我们只查询title.std字段，那么只有文档2会匹配。但是，当我们查询两个字段并将它们的分值通过bool查询进行合并的话，两份文档都能够匹配(title字段也匹配了)，而文档2的分值会更高一些(匹配了title.std字段)：
    GET /my_index/_search
    {
       "query": {
            "multi_match": {
                "query":  "jumping rabbits",
                "type":   "most_fields", <1>
                "fields": [ "title", "title.std" ]
            }
        }
    }
    <1> 在上述查询中，由于我们想合并所有匹配字段的分值，因此使用的类型为most_fields。这会让multi_match查询将针对两个字段的查询子句包含在一个bool查询中，而不是包含在一个dis_max查询中。
    {
      "hits": [
         {
            "_id": "2",
            "_score": 0.8226396, <1>
            "_source": {
               "title": "Jumping jack rabbits"
            }
         },
         {
            "_id": "1",
            "_score": 0.10741998, <1>
            "_source": {
               "title": "My rabbit jumps"
            }
         }
      ]
    }
    <1> 文档2的分值比文档1的高许多。
    我们使用了拥有宽泛形式的title字段来匹配尽可能多的文档 - 来增加召回率(Recall)，同时也使用了title.std字段作为信号来让最相关的文档能够拥有更靠前的排序(译注：增加了准确率(Precision))。
    每个字段对最终分值的贡献可以通过指定boost值进行控制。比如，我们可以提升title字段来让该字段更加重要，这也减小了其它信号字段的影响：
    GET /my_index/_search
    {
       "query": {
            "multi_match": {
                "query":       "jumping rabbits",
                "type":        "most_fields",
                "fields":      [ "title^10", "title.std" ] <1>
            }
        }
    }
    <1> boost=10让title字段的相关性比title.std更重要。

14.7 跨字段对象查询

    （1）跨字段实体搜索
    现在让我们看看一个常见的模式：跨字段实体搜索。类似person，product或者address这样的实体，它们的信息会分散到多个字段中。我们或许有一个person实体被索引如下：
    {
        "firstname":  "Peter",
        "lastname":   "Smith"
    }
    而address实体则是像下面这样：
    {
        "street": "5 Poland Street",
        "city": "London",
        "country": "United Kingdom",
        "postcode": "W1V 3DG"
    }
    这个例子也许很像在多查询字符串中描述的，但是有一个显著的区别。在多查询字符串中，我们对每个字段都使用了不同的查询字符串。在这个例子中，我们希望使用一个查询字符串来搜索多个字段。
    用户也许会搜索名为"Peter Smith"的人，或者名为"Poland Street W1V"的地址。每个查询的单词都出现在不同的字段中，因此使用dis_max/best_fields查询来搜索单个最佳匹配字段显然是不对的。

    （2）一个简单的方法
    实际上，我们想要依次查询每个字段然后将每个匹配字段的分值进行累加，这听起来很像bool查询能够胜任的工作：
    {
      "query": {
        "bool": {
          "should": [
            { "match": { "street":"Poland Street W1V" }},
            { "match": { "city": "Poland Street W1V" }},
            { "match": { "country":"Poland Street W1V" }},
            { "match": { "postcode":"Poland Street W1V" }}
          ]
        }
      }
    }
    对每个字段重复查询字符串很快就会显得冗长。我们可以使用multi_match查询进行替代，然后将type设置为most_fields来让它将所有匹配字段的分值合并：
    {
      "query": {
        "multi_match": {
          "query":       "Poland Street W1V",
          "type":        "most_fields",
          "fields":      [ "street", "city", "country", "postcode" ]
        }
      }
    }

    （3）使用most_fields存在的问题
    使用most_fields方法执行实体查询有一些不那么明显的问题：
        它被设计用来找到匹配任意单词的多数字段，而不是找到跨越所有字段的最匹配的单词。
        它不能使用operator或者minimum_should_match参数来减少低相关度结果带来的长尾效应。
        每个字段的词条频度是不同的，会互相干扰最终得到较差的排序结果。

14.8 以字段为中心查询

    上述提到的三个问题都来源于most_fields是以字段为中心(Field-centric)，而不是以词条为中心(Term-centric)：它会查询最多匹配的字段(Most matching fields)，而我们真正感兴趣的最匹配的词条(Most matching terms)。
    提示：best_fields同样是以字段为中心的，因此它也存在相似的问题。 首先我们来看看为什么存在这些问题，以及如何解决它们。

    （1）问题1：在多个字段中匹配相同的单词
    考虑一下most_fields查询是如何执行的：ES会为每个字段生成一个match查询，然后将它们包含在一个bool查询中。
    我们可以将查询传入到validate-query API中进行查看：
    GET /_validate/query?explain
    {
      "query": {
        "multi_match": {
          "query": "Poland Street W1V",
          "type": "most_fields",
          "fields": [ "street", "city", "country", "postcode" ]
        }
      }
    }
    它会产生下面的解释(explaination)：
    (street:poland   street:street   street:w1v)
    (city:poland     city:street     city:w1v)
    (country:poland  country:street  country:w1v)
    (postcode:poland postcode:street postcode:w1v)
    你可以发现能够在两个字段中匹配poland的文档会比在一个字段中匹配了poland和street的文档的分值要高。

    （2）问题2：减少长尾
    在精度控制(Controlling Precision)一节中，我们讨论了如何使用and操作符和minimum_should_match参数来减少相关度低的文档数量：
    {
        "query": {
            "multi_match": {
                "query": "Poland Street W1V",
                "type": "most_fields",
                "operator": "and", <1>
                "fields": [ "street", "city", "country", "postcode" ]
            }
        }
    }
    <1> 所有的term必须存在。
    但是，使用best_fields或者most_fields，这些参数会被传递到生成的match查询中。该查询的解释如下(译注：通过validate-query API)：
    (+street:poland   +street:street   +street:w1v)
    (+city:poland     +city:street     +city:w1v)
    (+country:poland  +country:street  +country:w1v)
    (+postcode:poland +postcode:street +postcode:w1v)
    换言之，使用and操作符时，所有的单词都需要出现在相同的字段中，这显然是错的！这样做可能不会有任何匹配的文档。

    （3）问题3：词条频度
    在什么是相关度(What is Relevance(relevance-intro))一节中，我们解释了默认用来计算每个词条的相关度分值的相似度算法TF/IDF：
    词条频度(Term Frequency):在一份文档中，一个词条在一个字段中出现的越频繁，文档的相关度就越高。
    倒排文档频度(Inverse Document Frequency): 一个词条在索引的所有文档的字段中出现的越频繁，词条的相关度就越低。 当通过多字段进行搜索时，TF/IDF会产生一些令人惊讶的结果。
    考虑使用first_name和last_name字段搜索"Peter Smith"的例子。Peter是一个常见的名字，Smith是一个常见的姓氏-它们的IDF都较低。但是如果在索引中有另外一个名为Smith Williams的人呢？Smith作为名字是非常罕见的，因此它的IDF值会很高！
    像下面这样的一个简单查询会将Smith Williams放在Peter Smith前面(译注：含有Smith Williams的文档分值比含有Peter Smith的文档分值高)，尽管Peter Smith明显是更好的匹配：
    {
        "query": {
            "multi_match": {
                "query":"Peter Smith",
                "type": "most_fields",
                "fields": [ "*_name" ]
            }
        }
    }
    smith在first_name字段中的高IDF值会压倒peter在first_name字段和smith在last_name字段中的两个低IDF值。

    解决方案：
    这个问题仅在我们处理多字段时存在。如果我们将所有这些字段合并到一个字段中，该问题就不复存在了。我们可以向person文档中添加一个full_name字段来实现：
    {
        "first_name":  "Peter",
        "last_name":   "Smith",
        "full_name":   "Peter Smith"
    }
    当我们只查询full_name字段时：
    拥有更多匹配单词的文档会胜过那些重复出现一个单词的文档。
    minimum_should_match和operator参数能够正常工作。
    first_name和last_name的倒排文档频度会被合并，因此smith无论是first_name还是last_name都不再重要。尽管这种方法能工作，可是我们并不想存储冗余数据。
    因此，ES为我们提供了两个解决方案 - 一个在索引期间，一个在搜索期间。下一节对它们进行讨论。

14.9 全字段查询

    在元数据：_all字段中，我们解释了特殊的_all字段会将其它所有字段中的值作为一个大字符串进行索引。尽管将所有字段的值作为一个字段进行索引并不是非常灵活。
    如果有一个自定义的_all字段用来索引人名，另外一个自定义的_all字段用来索引地址就更好了。
    ES通过字段映射中的copy_to参数向我们提供了这一功能：
    PUT /my_index
    {
        "mappings": {
            "person": {
                "properties": {
                    "first_name": {
                        "type":     "string",
                        "copy_to":  "full_name" <1>
                    },
                    "last_name": {
                        "type":     "string",
                        "copy_to":  "full_name" <1>
                    },
                    "full_name": {
                        "type":     "string"
                    }
                }
            }
        }
    }
    <1> first_name和last_name字段中的值会被拷贝到full_name字段中。
    有了这个映射，我们可以通过first_name字段查询名字，last_name字段查询姓氏，或者full_name字段查询姓氏和名字。
    提示：first_name和last_name字段的映射和full_name字段的索引方式的无关。full_name字段会从其它两个字段中拷贝字符串的值，然后仅根据full_name字段自身的映射进行索引。

14.10 跨字段查询

    （1）跨域查询
    如果你在索引文档前就能够自定义_all字段的话，那么使用_all字段就是一个不错的方法。但是，ES同时也提供了一个搜索期间的解决方案：
    使用类型为cross_fields的multi_match查询。cross_fields类型采用了一种以词条为中心(Term-centric)的方法，这种方法和best_fields
    及most_fields采用的以字段为中心(Field-centric)的方法有很大的区别。它将所有的字段视为一个大的字段，然后在任一字段中搜索每个词条。

    为了阐述以字段为中心和以词条为中心的查询的区别，看看以字段为中心的most_fields查询的解释(译注：通过validate-query API得到)：
    GET /_validate/query?explain
    {
        "query": {
            "multi_match": {
                "query":       "peter smith",
                "type":        "most_fields",
                "operator":    "and", <1>
                "fields":      [ "first_name", "last_name" ]
            }
        }
    }
    <1> operator设为了and，表示所有的词条都需要出现。
    对于一份匹配的文档，peter和smith两个词条都需要出现在相同的字段中，要么是first_name字段，要么是last_name字段：
    (+first_name:peter +first_name:smith)
    (+last_name:peter  +last_name:smith)
    而以词条为中心的方法则使用了下面这种逻辑：
    +(first_name:peter last_name:peter)
    +(first_name:smith last_name:smith)
    换言之，词条peter必须出现在任一字段中，同时词条smith也必须出现在任一字段中。
    cross_fields类型首先会解析查询字符串来得到一个词条列表，然后在任一字段中搜索每个词条。仅这个区别就能够解决在以字段为中心的查询中提到的3个问题中的2个，只剩下倒排文档频度的不同这一问题。
    幸运的是，cross_fields类型也解决了这个问题，从下面的validate-query请求中可以看到：
    GET /_validate/query?explain
    {
        "query": {
            "multi_match": {
                "query": "peter smith",
                "type":   "cross_fields", <1>
                "operator": "and",
                "fields": [ "first_name", "last_name" ]
            }
        }
    }
    <1> cross_fields 使用以词条为中心(Term-centric)进行匹配。
    它通过混合(Blending)字段的倒排文档频度来解决词条频度的问题：
    +blended("peter", fields: [first_name, last_name])
    +blended("smith", fields: [first_name, last_name])
    换言之，它会查找词条smith在first_name和last_name字段中的IDF值，然后使用两者中较小的作为两个字段最终的IDF值。因为smith是一个常见的姓氏，意味着它也会被当做一个常见的名字。
    提示：为了让cross_fields查询类型能以最佳的方式工作，所有的字段都需要使用相同的解析器。使用了相同的解析器的字段会被组合在一起形成混合字段(Blended Fields)。
    如果你包含了使用不同解析链(Analysis Chain)的字段，它们会以和best_fields相同的方式被添加到查询中。比如，如果我们将title字段添加到之前的查询中(假设它使用了一个不同的解析器)，得到的解释如下所示：
    (+title:peter +title:smith)
    (
      +blended("peter", fields: [first_name, last_name])
      +blended("smith", fields: [first_name, last_name])
    )
    当使用了minimum_should_match以及operator参数时，这一点尤为重要。

    （2）逐字段加权
    使用cross_fields查询相比使用自定义_all字段的一个优点是你能够在查询期间对个别字段进行加权。
    对于first_name和last_name这类拥有近似值的字段，也许加权是不必要的，但是如果你通过title和description字段来搜索书籍，那么你或许会给予title字段更多的权重。
    这可以通过前面介绍的caret(^)语法来完成：
    GET /books/_search
    {
        "query": {
            "multi_match": {
                "query":       "peter smith",
                "type":        "cross_fields",
                "fields":      [ "title^2", "description" ] <1>
            }
        }
    }
    <1> The title field has a boost of 2, while the description field has the default boost of 1.
    能够对个别字段进行加权带来的优势应该和对多个字段执行查询伴随的代价进行权衡，因为如果使用自定义的_all字段，那么只需要要对一个字段进行查询。选择能够给你带来最大收益的方案。

14.11 精确查询

    在结束对于多字段查询的讨论之前的最后一个话题是作为not_analyzed类型的精确值字段。在multi_match查询中将not_analyzed字段混合到analyzed字段中是没有益处的。
    原因可以通过validate-query进行简单地验证，假设我们将title字段设置为not_analyzed：
    GET /_validate/query?explain
    {
        "query": {
            "multi_match": {
                "query": "peter smith",
                "type":  "cross_fields",
                "fields": [ "title", "first_name", "last_name" ]
            }
        }
    }
    因为title字段时没有被解析的，它会以将整个查询字符串作为一个词条进行搜索！
    title:peter smith
    (
        blended("peter", fields: [first_name, last_name])
        blended("smith", fields: [first_name, last_name])
    )
    很显然该词条在title字段的倒排索引中并不存在，因此永远不可能被找到。在multi_match查询中避免使用not_analyzed字段。